{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a846fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from db_models import FilingTag, FileLocation, File\n",
    "from sqlalchemy import create_engine, func\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def get_db_engine():\n",
    "    \"\"\"Create and return a SQLAlchemy engine for the project database.\"\"\"\n",
    "    conn_string = (\n",
    "        f\"postgresql+psycopg://{os.getenv('PROJECT_DB_USERNAME')}:{os.getenv('PROJECT_DB_PASSWORD')}\"\n",
    "        f\"@{os.getenv('PROJECT_DB_HOST')}:{os.getenv('PROJECT_DB_PORT')}/{os.getenv('PROJECT_DB_NAME')}\"\n",
    "    )\n",
    "    return create_engine(conn_string)\n",
    "\n",
    "# Configure your database session\n",
    "engine = get_db_engine()\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "def file_tag_file_locations(filing_tag):\n",
    "    \"\"\"\n",
    "    Find all FileLocation entries where file_server_directories contains the filing tag label.\n",
    "    \n",
    "    Args:\n",
    "        filing_tag (FilingTag): The filing tag object to search for\n",
    "    \n",
    "    Returns:\n",
    "        list: FileLocation entries matching the criteria\n",
    "    \"\"\"\n",
    "    search_pattern = f\"{filing_tag.label} - \"\n",
    "    \n",
    "    # Query for FileLocation entries where file_server_directories contains the pattern\n",
    "    locations = session.query(FileLocation).filter(\n",
    "        FileLocation.file_server_directories.like(f\"%{search_pattern}%\")\n",
    "    ).all()\n",
    "    \n",
    "    return locations\n",
    "\n",
    "# Get all filing tags\n",
    "all_filing_tags = session.query(FilingTag).all()\n",
    "\n",
    "# Create a list to store results\n",
    "results = []\n",
    "\n",
    "# Iterate through all filing tags\n",
    "for tag in all_filing_tags:\n",
    "    # Get matching file locations\n",
    "    locations = file_tag_file_locations(tag)\n",
    "    count = len(locations)\n",
    "    \n",
    "    # Add to results\n",
    "    results.append({\n",
    "        'tag': tag.label,\n",
    "        'description': tag.description,\n",
    "        'file_locations_count': count\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame for better visualization\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# Sort by count in descending order\n",
    "df_results = df_results.sort_values('file_locations_count', ascending=False)\n",
    "\n",
    "# Display summary statistics\n",
    "print(f\"Found {len(df_results)} filing tags with {df_results['file_locations_count'].sum()} total file locations\")\n",
    "\n",
    "# Display top tags by location count\n",
    "display(df_results.head(20))\n",
    "\n",
    "# Visualize the top 15 tags by file location count\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_tags = df_results.head(15)\n",
    "sns.barplot(x='file_locations_count', y='tag', data=top_tags)\n",
    "plt.title('Top 15 Filing Tags by File Location Count')\n",
    "plt.xlabel('Number of File Locations')\n",
    "plt.ylabel('Filing Tag')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06eea05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create spreadsheet from df_results\n",
    "df_results.to_csv('filing_tags_file_locations_summary.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9fc8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import psycopg\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve database credentials from environment variables\n",
    "DB_NAME = os.getenv(\"DB_NAME\")\n",
    "DB_USER = os.getenv(\"DB_USER\")\n",
    "DB_PASSWORD = os.getenv(\"DB_PASSWORD\")\n",
    "DB_HOST = os.getenv(\"DB_HOST\")\n",
    "\n",
    "# Establish a connection to the database\n",
    "conn = psycopg.connect(\n",
    "    dbname=DB_NAME,\n",
    "    user=DB_USER,\n",
    "    password=DB_PASSWORD,\n",
    "    host=DB_HOST\n",
    ")\n",
    "\n",
    "# Create a cursor to execute SQL commands\n",
    "cur = conn.cursor()\n",
    "\n",
    "# SQL statements to create tables\n",
    "sql_commands = [\n",
    "    \"\"\"\n",
    "    CREATE TABLE prototype_runs (\n",
    "      run_id SERIAL PRIMARY KEY,\n",
    "      model_name TEXT NOT NULL,\n",
    "      model_version TEXT NOT NULL,\n",
    "      algorithm TEXT NOT NULL,\n",
    "      hyperparams JSONB,\n",
    "      tag_filter TEXT,\n",
    "      created_at TIMESTAMPTZ DEFAULT now()\n",
    "    );\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    CREATE TABLE prototype_members (\n",
    "      run_id INTEGER REFERENCES prototype_runs(run_id) ON DELETE CASCADE,\n",
    "      tag TEXT REFERENCES filing_tags(label),\n",
    "      prototype_id SMALLINT DEFAULT 0,\n",
    "      file_id INTEGER REFERENCES files(id),\n",
    "      PRIMARY KEY (run_id, tag, prototype_id, file_id)\n",
    "    );\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    ALTER TABLE tag_prototypes ADD COLUMN run_id INTEGER\n",
    "      REFERENCES prototype_runs(run_id) ON DELETE SET NULL;\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    CREATE TABLE prototype_run_metrics (\n",
    "      run_id INTEGER REFERENCES prototype_runs(run_id) ON DELETE CASCADE,\n",
    "      metric_name TEXT,\n",
    "      value NUMERIC,\n",
    "      split TEXT,\n",
    "      PRIMARY KEY (run_id, metric_name, split)\n",
    "    );\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "# Execute each command\n",
    "for command in sql_commands:\n",
    "    cur.execute(command)\n",
    "\n",
    "# Commit changes and close the connection\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c39ad64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from itertools import islice\n",
    "\n",
    "\n",
    "def visualize_directory_tree(\n",
    "    dir_path: Path,\n",
    "    level: int = -1,\n",
    "    limit_to_directories: bool = False,\n",
    "    length_limit: int = 1000000,\n",
    "    exclusion_list: list = None\n",
    "):\n",
    "    \"\"\"Given a directory Path object print a visual tree structure, with optional exclusions.\"\"\"\n",
    "    space = '    '\n",
    "    branch = '│   '\n",
    "    # pointers:\n",
    "    tee = '├── '\n",
    "    last = '└── '\n",
    "\n",
    "    dir_path = Path(dir_path)  # accept string coerceable to Path\n",
    "    files = 0\n",
    "    directories = 0\n",
    "    exclusion_set = set(exclusion_list) if exclusion_list else set()\n",
    "\n",
    "    def inner(dir_path: Path, prefix: str = '', level=-1):\n",
    "        nonlocal files, directories\n",
    "        if not level:\n",
    "            return  # 0, stop iterating\n",
    "        if limit_to_directories:\n",
    "            contents = [d for d in dir_path.iterdir() if d.is_dir() and d.name not in exclusion_set]\n",
    "        else:\n",
    "            contents = [d for d in dir_path.iterdir() if d.name not in exclusion_set]\n",
    "        pointers = [tee] * (len(contents) - 1) + [last] if contents else []\n",
    "        for pointer, path in zip(pointers, contents):\n",
    "            if path.is_dir():\n",
    "                yield prefix + pointer + path.name\n",
    "                directories += 1\n",
    "                extension = branch if pointer == tee else space\n",
    "                yield from inner(path, prefix=prefix + extension, level=level - 1)\n",
    "            elif not limit_to_directories:\n",
    "                yield prefix + pointer + path.name\n",
    "                files += 1\n",
    "\n",
    "    print(dir_path.name)\n",
    "    iterator = inner(dir_path, level=level)\n",
    "    for line in islice(iterator, length_limit):\n",
    "        print(line)\n",
    "    if next(iterator, None):\n",
    "        print(f'... length_limit, {length_limit}, reached, counted:')\n",
    "    print(f'\\n{directories} directories' + (f', {files} files' if files else ''))\n",
    "# exclude irrelevant directories\n",
    "exclude_dirs = [\n",
    "    '.venv',\n",
    "    '__pycache__',\n",
    "    'dev\\__pycache__',\n",
    "    '.git'\n",
    "]\n",
    "\n",
    "visualize_directory_tree(\n",
    "    dir_path= os.getcwd(),\n",
    "    exclusion_list= exclude_dirs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421e5ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from text_extraction.pdf_extraction import PDFTextExtractor\n",
    "\n",
    "def test_pdf_text_extraction(directory_path):\n",
    "    \"\"\"\n",
    "    Test PDF text extraction on all files in the given directory.\n",
    "    \n",
    "    Args:\n",
    "        directory_path (str): Path to the directory containing PDF files.\n",
    "    \"\"\"\n",
    "    extractor = PDFTextExtractor()\n",
    "    for root, _, files in os.walk(directory_path):\n",
    "        for file in files:\n",
    "            if file.lower().endswith('.pdf'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    print(f\"Extracting text from: {file_path}\")\n",
    "                    text = extractor(file_path)\n",
    "                    print(f\"Extracted text (first 500 characters):\\n{text[:500]}\\n\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to extract text from {file_path}: {e}\")\n",
    "\n",
    "# Example usage\n",
    "test_directory = \"path/to/your/pdf/directory\"\n",
    "test_pdf_text_extraction(test_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02122255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell is for populating /test_files with test files from the server\n",
    "import os\n",
    "import shutil\n",
    "from db_models import FileLocation, File, get_db_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy.sql import func, or_\n",
    "\n",
    "SERVER_MOUNT_LOCATION = r\"N:\\PPDO\\Records\"\n",
    "\n",
    "ext_lists_list = [\n",
    "['pdf'],\n",
    "[\"html\", \"htm\", \"mhtml\", \"mht\"],\n",
    "[\"eml\", \"msg\"],\n",
    "[\"png\", \"jpg\", \"jpeg\", \"tif\", \"tiff\", \"bmp\", \"gif\"],\n",
    "[\"docx\", \"docm\", \"doc\", \"rtf\"],\n",
    "[\"xlsx\", \"xlsm\", \"xls\", \"xlsb\", \"ods\", \"csv\", \"tsv\"],\n",
    "['txt', 'md', 'log', 'csv', 'json', 'xml', 'yaml', 'yml', 'ini', 'cfg', 'conf']\n",
    "]\n",
    "\n",
    "def get_test_file_locations(session, n, size_limit, ext_list):\n",
    "    \"\"\"\n",
    "    Get random test files from the database based on specified criteria.\n",
    "    \"\"\"\n",
    "    query = (\n",
    "        session\n",
    "        .query(FileLocation)\n",
    "        .join(File, FileLocation.file)\n",
    "        .filter(\n",
    "            File.size < size_limit,\n",
    "            FileLocation.file_server_directories.isnot(None)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    if ext_list:\n",
    "        ext_filters = [\n",
    "            FileLocation.filename.ilike(f\"%.{ext}\") \n",
    "            for ext in ext_list\n",
    "        ]\n",
    "        query = (\n",
    "            query\n",
    "            .filter(or_(*ext_filters))\n",
    "            .order_by(func.random())\n",
    "        )\n",
    "\n",
    "    return query.limit(n).all()\n",
    "\n",
    "def save_test_files_to_directory(session, n, size_limit, ext_lists_list, destintation = os.path.join(os.getcwd(), \"test_files\")):\n",
    "    \"\"\"\n",
    "    Save test files to a specified directory based on given criteria.\n",
    "    \n",
    "    Args:\n",
    "        session: SQLAlchemy session object.\n",
    "        n (int): Number of files to retrieve.\n",
    "        size_limit (int): Maximum file size in bytes.\n",
    "        ext_lists_list: List of lists containing file extensions.\n",
    "        base_dir (str): Base directory to save the test files.\n",
    "    \"\"\"\n",
    "    for ext_list in ext_lists_list:\n",
    "        locations = get_test_file_locations(session, n, size_limit, ext_list)\n",
    "        for loc in locations:\n",
    "            file_path = loc.local_filepath(SERVER_MOUNT_LOCATION)\n",
    "            if file_path and file_path.exists():\n",
    "                dest_path = os.path.join(destintation, loc.filename)\n",
    "                shutil.copy2(file_path, dest_path)\n",
    "                print(f\"Copied {loc.filename} to {dest_path}\")\n",
    "                continue\n",
    "\n",
    "            if file_path and not file_path.exists():\n",
    "                print(f\"File {file_path} does not exist, skipping.\")\n",
    "                continue\n",
    "\n",
    "        print(f\"Test files saved to {destintation}\")\n",
    "\n",
    "\n",
    "size_limit = 150 * 1024 * 1024  # 150 MB\n",
    "n = 15  # Number of files per extension\n",
    "destintation = os.path.join(os.getcwd(), \"test_files\")\n",
    "session = sessionmaker(bind=get_db_engine())()\n",
    "\n",
    "save_test_files_to_directory(\n",
    "    session=session,\n",
    "    n=n,\n",
    "    size_limit=size_limit,\n",
    "    ext_lists_list=ext_lists_list,\n",
    "    destintation=destintation\n",
    ")           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a851098e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adankert\\projects\\file_code_tagger\\text_extraction\\image_extraction.py:45: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  Full path to tesseract.exe if not on PATH. (eg r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62656d999cfd44f69fd2cb9f678b6a3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping good_test_files, not a file.\n",
      "Extracting text from orientation_hand_written_mess.tif using ImageTextExtractor\n",
      "Extracted text (first 800 characters) from orientation_hand_written_mess.tif:\n",
      "aS HO ‘AFT OL\n",
      "\n",
      "*\n",
      "\n",
      "Gc 233-0) Ber gag\n",
      "nee Grae als Broa. §\n",
      "HS 1. m\n",
      "\n",
      "Tey :\n",
      "— a\n",
      "\n",
      "&\n",
      "e\n",
      "e\n",
      "\n",
      "Sey\n",
      "\n",
      ",\n",
      "\n",
      "2'S9-2t ‘laa = NEN\n",
      "be‘122 CLNO)ANI\n",
      "BSO'SLL CNEANI\n",
      "\n",
      "‘SAL ‘AaisNi sailiniin\n",
      "\n",
      "/ b'S22 Fa\n",
      "f. GI Nivea HONSUL\n",
      ": ; y Ue ww\n",
      "if). OAH on | 500025 + o x\n",
      "Monaino ad OL Sie Sle BOL Qe 1B aveesise pB ery ran -\n",
      "o9b Ad dowd Sy 3S 6g, om la a ASGNIS TG $19 SEs tah ot /\n",
      "iy Be Sle ou ~o = OO'GIL MC $5 fd; aK da Xf\n",
      "BOS SZ Oe Se la GNdd @ obisi at ms @ iw .\n",
      "ips fej rs) o § 9200-3 Af’ dio\\ ; rae .\n",
      "x o 39 > 8 a DOdNVas 5:48) (hem BA FT| 260 Sere 7\n",
      "lB ge. 5 20\"@aL aI a ep oR ae\n",
      "Oo AS aN aS bp Se ORS ris Oh j Soe a AO\n",
      "gov av Ne Pecos 6 | a a :\n",
      "\n",
      "wots, | dO NOLWNNILNOD Yad eat\n",
      "hla SANIMWIG DNIAWMd Gy o> $eere anya ~\n",
      "| TWOIl0313 “WIINVHIAW. aS 55 SIL BY Hin\n",
      "FO bLL AT _—— —— -_ ___ ——_— jaS2 :\n",
      "ce]\n",
      "Srore a e\n",
      ". i ,b,0% oh Ny 8\n",
      "\n",
      "\n",
      "Extracting text from pdf_table.pdf using PDFTextExtractor\n",
      "Extracted text (first 800 characters) from pdf_table.pdf:\n",
      "KRESGE BUILDINGS FOR CONDITION ASSESSMENT cpsm 9-17-15 Total Area Department Area Pct% RG* w/o RG* State Fee Aux Arts Division Administration 679 0.50% 679 679 Colleges Housing Administration 1588 1.20% 1,588 1,588 Counseling and Psychological Services 513 0.40% 513 513 Film and Digital Media Department 4089 3.20% 4,089 4,089 General Arts 390 0.30% 390 390 General Assignment Classrooms 4406 3.40% 4,406 4,406 General Physical and Biological Sciences 1536 1.20% 1,536 1,536 History of Art and Visual Culture Department 534 0.40% 534 534 Housing Commercial Services 3188 2.50% 3,188 3,188 Instructional Computing Laboratories 421 0.30% 421 421 Kresge College Administration 4516 3.50% 4,516 4,516 Kresge College SLRS Administration 6383 5.00% 6,383 6,383 Physical Plant 159 0.10% 159 159 Provost- Un\n",
      "\n",
      "Extracting text from scanned_pink_paper.pdf using PDFTextExtractor\n",
      "Extracted text (first 800 characters) from scanned_pink_paper.pdf:\n",
      "IMPOFTANT: SEEI REVERSE FOF INFOFMATION REGARDING MECHANICS LIEN LAWS, CFEDIT SALE INFORMATION, & TEFMS AND CONDITIONS OF SALE. Business Address: 146 ENCINAL STREET SANTACBUZ, CA95060 8311426-7280 3?- y'a¿ 4r4û4.ao &aozeæ e eclillrt4? Sq'þ//?, ?oø, Mailing Address: P.O. Box 507 Santa Cruz, CA 9506'1 CAUTION: Freshly mixed concrete may cause skin irritatlon on prolonged exposure. Avoid direct contact where possible and wash exposed skin areas promptly with water, lf any cemenllous mater¡als get into the eye, rlnse immediately and repeatedly w¡th water and get prompt medlcal attention. Keep out ol reach of chlldren. SHIP TO: nilE Mtx No. THIS YDSJIIETERS ORD'D usE DRIVER/TRUCK IIAP COORDINAIE PLANT/TFANSACTION f DATE NO. OF LOADS ACCUI'. YDS,/ITETERS BATCH T WATEF TFIIi T|CKEÍ NUilBEN WEIGHM\n",
      "\n",
      "Extracting text from UCSC Crown MM Estimate Reconciliation - 8.7.17.xlsx using SpreadsheetTextExtractor\n",
      "Extracted text (first 800 characters) from UCSC Crown MM Estimate Reconciliation - 8.7.17.xlsx:\n",
      "=== Sheet: Addl Scope Cost Study === UCSC Crown College Unnamed: 1 Unnamed: 2 Add-Scope/Costs Study 2017-06-12 00:00:00 Note: items listed below are added scope, not included in original 2015 cost estimate Description Updated Cost Added Apartment Layout (Bed and Bath) Construction Value (escalation included) 1707000 A/E Fee PP&C, Special Item Subtotal: 1707000.0 Added \"purple pipe\" (ASA 02) Construction Value (escalation included) 144402 A/E Fee PP&C, Special Item Subtotal: 144402.0 Added Power Feeder Cabinet (ASA 04) Construction Value (escalation included) 146354 A/E Fee PP&C, Special Item Subtotal: 146354.0 Added Site Domestic Water and Gas (ASA 06) Construction Value (escalation included) 1640747 A/E Fee PP&C, Special Item Subtotal: 1640747.0 Added WAPs in every room (ASA 07) Construct\n",
      "\n",
      "Extracting text from wrong_orientation_test.TIF using ImageTextExtractor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adankert\\projects\\file_code_tagger\\.venv\\Lib\\site-packages\\PIL\\Image.py:3452: DecompressionBombWarning: Image size (175007232 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted text (first 800 characters) from wrong_orientation_test.TIF:\n",
      "aaion sv aes\n",
      "\n",
      "MALVMGGNVA st\n",
      "\n",
      "SNOILDES  ONWid asvHD VINYOAIVS AO ALISMBAINN | 17797986 290-986 taauts Heng bor SUENIONA TaNLonus\n",
      "\n",
      "RLITILN Lave — WWOINVHDEW LINA SAONAIDS TWen.ivwN | SLOALIHDYV © NATTY @ NAHSNV [sossy 2 onvA‘vyIny/NITAL\n",
      "\n",
      "8I18T-b- 4INVO- dV\n",
      "\n",
      "SNOISIAaY\n",
      "bob ‘eT\n",
      "\n",
      "| ane\n",
      "“a= 48-8\n",
      "\n",
      "pres or |G\n",
      "\n",
      "spre Fr scon\n",
      "\n",
      "2p wonocr® IP\n",
      "woe aaa\n",
      "\n",
      "=F + e7res Gia\n",
      "NV7aS FSVHD ALIVILA LAVAL\n",
      "\n",
      "@no « suv one 3 sso 920 2\n",
      "omm/pedE op posit Biuame omurrnei we True pEErD ALIA Boren! CLONE WIND ITE\n",
      "\n",
      "‘SRO\n",
      "BPOO7S GAA\n",
      "BPP POOPY anE PACOE BBFC HAIDA MEI POTTS 19) OL BLITE ATMS DIY bie“\n",
      "pon Fe 'SBIon\n",
      "poole, Bors renee Bnet\n",
      "of ‘wroree Sarre so tiee ie\n",
      "enn At oe >\n",
      "A somonwere\n",
      "Smee WM) PPO Ta PIF ZIOOT DPS ured OD ars zox200 roe BOO 774\n",
      "SPSI7O One OT Ia PEL TIO POR AL BITOR DP SOS FOP 7 Dhak io Se 70 TDISAL\n",
      "PROG BEX P\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "import traceback \n",
    "import tempfile\n",
    "from text_extraction.pdf_extraction import PDFTextExtractor\n",
    "from text_extraction.basic_extraction import TextFileTextExtractor, get_extractor_for_file\n",
    "from text_extraction.image_extraction import ImageTextExtractor\n",
    "from text_extraction.office_doc_extraction import PresentationTextExtractor, SpreadsheetTextExtractor, WordFileTextExtractor\n",
    "from text_extraction.web_extraction import HtmlTextExtractor, EmailTextExtractor\n",
    "from text_extraction.extraction_utils import common_char_replacements, strip_diacritics, normalize_unicode\n",
    "from logging_setups import setup_logger\n",
    "\n",
    "setup_logger(name=\"NotebookLogger\", notebook=True, level=logging.DEBUG)\n",
    "\n",
    "import pytesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "# Initialize extractors for different file types\n",
    "pdf_extractor = PDFTextExtractor()\n",
    "txt_extractor = TextFileTextExtractor()\n",
    "image_extractor = ImageTextExtractor()\n",
    "presentation_extractor = PresentationTextExtractor()\n",
    "spreadsheet_extractor = SpreadsheetTextExtractor()\n",
    "word_extractor = WordFileTextExtractor()\n",
    "html_extractor = HtmlTextExtractor()\n",
    "email_extractor = EmailTextExtractor()\n",
    "\n",
    "extractors_list = [\n",
    "    pdf_extractor,\n",
    "    txt_extractor,\n",
    "    image_extractor,\n",
    "    presentation_extractor,\n",
    "    spreadsheet_extractor,\n",
    "    word_extractor,\n",
    "    html_extractor,\n",
    "    email_extractor\n",
    "]\n",
    "display_text_len = 800\n",
    "test_extraction_path = os.path.join(os.getcwd(), \"test_files\")\n",
    "\n",
    "for file in os.listdir(test_extraction_path):\n",
    "    file_path = os.path.join(test_extraction_path, file)\n",
    "    def text_assessment(extracted_text):\n",
    "        if not extracted_text:\n",
    "            print(f\"No text extracted from {file} in temporary directory\")\n",
    "        elif len(extracted_text) > display_text_len:\n",
    "            print(f\"Extracted text (first {display_text_len} characters) from {file}:\\n{extracted_text[:display_text_len]}\\n\")\n",
    "        else:\n",
    "            print(f\"Extracted text from {file}:\\n{extracted_text}\\n\")\n",
    "\n",
    "    if not os.path.isfile(file_path):\n",
    "        print(f\"Skipping {file}, not a file.\")\n",
    "        continue\n",
    "    \n",
    "    extractor = get_extractor_for_file(file_path=file_path, extractors=extractors_list)\n",
    "    if extractor:\n",
    "        try:\n",
    "            print(f\"Extracting text from {file} using {extractor.__class__.__name__}\")\n",
    "            text = extractor(file_path)\n",
    "            text_assessment(text)\n",
    "        \n",
    "        except PermissionError as pe:\n",
    "            # Handle PermissionError by copying the file to a temporary directory\n",
    "            temp_dir = tempfile.gettempdir()\n",
    "            temp_file_path = os.path.join(temp_dir, file)\n",
    "            shutil.copy2(file_path, temp_file_path)\n",
    "            print(f\"Copied {file} to temporary directory: {temp_file_path}\")\n",
    "            \n",
    "            # Retry extraction from the temporary file\n",
    "            try:\n",
    "                text = extractor(temp_file_path)\n",
    "                text = common_char_replacements(text)\n",
    "                text = strip_diacritics(text)\n",
    "                text = normalize_unicode(text)\n",
    "                text_assessment(text)\n",
    "\n",
    "            except Exception as e:\n",
    "                raise Exception(f\"Failed to extract text from {file} in temporary directory: {e}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "\n",
    "            print(f\"Failed to extract text from {file}: {e}\")\n",
    "            traceback.print_exc()\n",
    "    else:\n",
    "        print(f\"No suitable extractor found for {file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c3ac64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
